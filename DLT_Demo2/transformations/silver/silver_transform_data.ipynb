{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df795eda-c27f-48b3-93f3-2b6363a1e77e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt \n",
    "from pyspark.sql.functions import * \n",
    "\n",
    "# STREAMING VIEW\n",
    "@dlt.view(\n",
    "    name = \"sales_silver_view\"\n",
    ")\n",
    "def sales_silver_view():\n",
    "    df_sales = spark.readStream.table(\"sales_bronze\")\n",
    "    df_sales = df_sales.withColumn(\"pricePerSale\",round(col(\"total_amount\")/col(\"quantity\"),2))\n",
    "    df_sales = df_sales.withColumn(\"processDate\",current_timestamp())\n",
    "    return df_sales\n",
    "\n",
    "\n",
    "\n",
    "# SALES SILVER TABLE (WITH UPSERT)\n",
    "dlt.create_streaming_table(name = 'sales_silver')\n",
    "\n",
    "dlt.create_auto_cdc_flow(\n",
    "    target = 'sales_silver',\n",
    "    source = 'sales_silver_view',\n",
    "    keys = ['sales_id'],\n",
    "    sequence_by = col('processDate'),\n",
    "    stored_as_scd_type = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "677d3d30-bf51-4f82-b663-973a8eeee7e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt \n",
    "from pyspark.sql.functions import * \n",
    "\n",
    "# STREAMING VIEW\n",
    "@dlt.view(\n",
    "    name = \"stores_silver_view\"\n",
    ")\n",
    "def stores_silver_view():\n",
    "    df_str = spark.readStream.table(\"stores_bronze\")\n",
    "    df_str = df_str.withColumn(\"store_name\",regexp_replace(col(\"store_name\"),\"_\",\"\"))\n",
    "    df_str = df_str.withColumn(\"processDate\",current_timestamp())\n",
    "    return df_str\n",
    "\n",
    "\n",
    "\n",
    "# STORES SILVER TABLE (WITH UPSERT)\n",
    "dlt.create_streaming_table(name = 'stores_silver')\n",
    "\n",
    "dlt.create_auto_cdc_flow(\n",
    "    target = 'stores_silver',\n",
    "    source = 'stores_silver_view',\n",
    "    keys = ['store_id'],\n",
    "    sequence_by = col('processDate'),\n",
    "    stored_as_scd_type = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75fccb8e-651f-4cd0-a45f-82f92d869e1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt \n",
    "from pyspark.sql.functions import * \n",
    "\n",
    "# STREAMING VIEW\n",
    "@dlt.view(\n",
    "    name = \"products_silver_view\"\n",
    ")\n",
    "def products_silver_view():\n",
    "    df_prod = spark.readStream.table(\"products_bronze\")\n",
    "    df_prod = df_prod.withColumn(\"processDate\",current_timestamp())\n",
    "    return df_prod\n",
    "\n",
    "\n",
    "\n",
    "# PRODUCTS SILVER TABLE (WITH UPSERT)\n",
    "dlt.create_streaming_table(name = 'products_silver')\n",
    "\n",
    "dlt.create_auto_cdc_flow(\n",
    "    target = 'products_silver',\n",
    "    source = 'products_silver_view',\n",
    "    keys = ['product_id'],\n",
    "    sequence_by = col('processDate'),\n",
    "    stored_as_scd_type = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "938970d5-5fb2-48b7-b333-9a318be7573a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt \n",
    "from pyspark.sql.functions import * \n",
    "\n",
    "# STREAMING VIEW\n",
    "@dlt.view(\n",
    "    name = \"customers_silver_view\"\n",
    ")\n",
    "def customers_silver_view():\n",
    "    df_cust = spark.readStream.table(\"customers_bronze\")\n",
    "    df_cust = df_cust.withColumn(\"name\",upper(col(\"name\")))\n",
    "    df_cust = df_cust.withColumn(\"domain\",split(col(\"email\"),\"@\")[1])\n",
    "    df_cust = df_cust.withColumn(\"processDate\",current_timestamp())\n",
    "    return df_cust\n",
    "\n",
    "\n",
    "\n",
    "# CUSTOMERS SILVER TABLE (WITH UPSERT)\n",
    "dlt.create_streaming_table(name = 'customers_silver')\n",
    "\n",
    "dlt.create_auto_cdc_flow(\n",
    "    target = 'customers_silver',\n",
    "    source = 'customers_silver_view',\n",
    "    keys = ['customer_id'],\n",
    "    sequence_by = col('processDate'),\n",
    "    stored_as_scd_type = 1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_transform_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
